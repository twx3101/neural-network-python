import numpy as np

from src.fcnet import FullyConnectedNet
# from fcnet import FullyConnectedNet

from src.utils.solver import Solver
from src.utils.data_utils import get_CIFAR10_data

"""
TODO: Overfit the network with 50 samples of CIFAR-10
"""
###########################################################################
#                           BEGIN OF YOUR CODE                            #
###########################################################################
#data_input = get_CIFAR10_data(50,50,10)
#print(type(data_input))
#print(data_input.keys())
'''
data = {
  'X_train': # training data
  'y_train': # training labels
  'X_val': # validation data
  'y_val': # validation labels
}
model = MyAwesomeModel(hidden_size=100, reg=10)
solver = Solver(model, data,
                update_rule='sgd',
                optim_config={
                  'learning_rate': 1e-3,
                },
                lr_decay=0.95,
                num_epochs=10, batch_size=100,
                print_every=100)
solver.train()

class FullyConnectedNet(object):
    """
    Implements a fully-connected neural networks with arbitrary size of
    hidden layers. For a network with N hidden layers, the architecture would
    be as follows:
    [linear - relu - (dropout)] x (N - 1) - linear - softmax
    The learnable params are stored in the self.params dictionary and are
    learned with the Solver.
    """
    def __init__(self, hidden_dims, input_dim=32*32*3, num_classes=10,
                 dropout=0, reg=0.0, weight_scale=1e-2, dtype=np.float32,
                 seed=None):
'''

# model = FullyConnectedNet(2,[20,30])
# solver = Solver(model
print(" ::::::::::::::::::::::::::::")
print(" ::::::::::::::::::::::::::::")
print(" ::::::::::::::::::::::::::::")
print(" ::::::::::::::::::::::::::::")
print(" ::::::::::::::::::::::::::::")

##############################################################################
#                             END OF YOUR CODE                               #
##############################################################################
